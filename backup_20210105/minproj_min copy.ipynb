{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### 0. 필요한 라이브러리 Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import nltk\n",
    "import time\n",
    "from pykospacing import spacing\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "import kss\n",
    "#from konlpy.tag import Kkma  \n",
    "from konlpy.tag import Twitter\n",
    "from eunjeon import Mecab\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# %appdata%\\nltk_data\\corpora\\stopwords\n",
    "# korean 파일을 생성하여 복사함\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "twitter = Twitter()\n",
    "#kkma = Kkma()\n",
    "mecab = Mecab('C://mecab//mecabrc')\n",
    "okt = Okt()\n",
    "\n",
    "\n",
    "# 한글출력\n",
    "#matplotlib.rc('font', family='AppleGothic')  # MacOS\n",
    "matplotlib.rc('font', family='Malgun Gothic')  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "source": [
    "### 1. 통합된 원본 데이터 파일을 읽어온다"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50568, 21)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50568 entries, 0 to 50567\nData columns (total 21 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   제목                              50568 non-null  object \n 1   저자                              50568 non-null  object \n 2   발행기관                            50568 non-null  object \n 3   학술지명                            50568 non-null  object \n 4   권호사항                            50568 non-null  object \n 5   발행연도                            50568 non-null  int64  \n 6   작성언어                            50568 non-null  object \n 7   주제어                             26933 non-null  object \n 8   KDC                             11761 non-null  float64\n 9   등재정보                            13083 non-null  object \n 10  자료형태                            50568 non-null  object \n 11  발행기관 URL                        22715 non-null  object \n 12  수록면                             50568 non-null  object \n 13  KCI 피인용횟수                       9042 non-null   float64\n 14  비고                              0 non-null      float64\n 15  중단사유                            180 non-null    object \n 16  제공처                             50453 non-null  object \n 17  소장기관                            10783 non-null  object \n 18  국문 초록 (Abstract)                10447 non-null  object \n 19  다국어 초록 (Multilingual Abstract)  25062 non-null  object \n 20  목차                              28402 non-null  object \ndtypes: float64(3), int64(1), object(17)\nmemory usage: 8.1+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ROOT_DIR = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "dataset = pd.read_csv(os.path.join(ROOT_DIR, \"dataset/one.csv\"))\n",
    "\n",
    "print(dataset.shape)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  제목  \\\n",
       "0                       전기 이륜자동차 분류기준 현황 : 자동차관리법 중심   \n",
       "1             자동차 사회의 환경과 에너지 문제 = 자동차 엔진 기술의 역사적 동향   \n",
       "2  수소 연료전지 자동차의 충돌 및 화재안전성 관련 연구동향 = Trends on Cr...   \n",
       "3  차세대 자동차 개발의 Plastic Hood 설계 및 CAE해석 = Plastic ...   \n",
       "4  자동차 산업의 역사와 급변하는 기술에 대응한 교육의 바람직한 방향에 관한 연구 = ...   \n",
       "\n",
       "                                                  저자      발행기관  \\\n",
       "0                                                정윤재  한국자동차공학회   \n",
       "1                                  김영길(Yong Kil Kim)  한국자동차공학회   \n",
       "2  임재문(Jae Moon Lim),장형진(Hyung Jin Chang),김규현(Gyu...  한국자동차공학회   \n",
       "3  황태원(Taewon Hwang),최치훈(Chihoon Choi),박상선(Sangsu...  한국자동차공학회   \n",
       "4                                황경수(Kyungsoo Whang)  한국자동차공학회   \n",
       "\n",
       "                     학술지명                     권호사항  발행연도    작성언어  \\\n",
       "0       한국자동차공학회 Workshop   Vol.2011No.9[2011]\\r\\n  2011  Korean   \n",
       "1     한국자동차공학회 학술대회 및 전시회  Vol.2014No.11[2014]\\r\\n  2014  Korean   \n",
       "2  한국자동차공학회 춘 추계 학술대회 논문집      Vol.-No.-[2008]\\r\\n  2008  Korean   \n",
       "3  한국자동차공학회 춘 추계 학술대회 논문집      Vol.-No.-[2006]\\r\\n  2006  Korean   \n",
       "4       한국자동차공학회 Workshop   Vol.2001No.-[2001]\\r\\n  2001  Korean   \n",
       "\n",
       "                                                 주제어    KDC 등재정보  ...  \\\n",
       "0                                                NaN  556.0  NaN  ...   \n",
       "1  Internal Combustion Engine(내연기관),Energy (에너지),...    NaN  NaN  ...   \n",
       "2  Hydrogen Fuel Cell Vehicle(수소 연료전지 자동차),Crash ...    NaN  NaN  ...   \n",
       "3  HOOD(본넷트),Distance(이동량),LS-DYNA(구조해석),MOLDFLOW...    NaN  NaN  ...   \n",
       "4                                                NaN    NaN  NaN  ...   \n",
       "\n",
       "              발행기관 URL        수록면 KCI 피인용횟수  비고  중단사유     제공처 소장기관  \\\n",
       "0  http://www.ksae.org       1-14       NaN NaN   NaN   DBpia  NaN   \n",
       "1                  NaN  1477-1477       NaN NaN   NaN   DBpia  NaN   \n",
       "2  http://www.ksae.org  1253-1258       NaN NaN   NaN   DBpia  NaN   \n",
       "3  http://www.ksae.org  2032-2032       NaN NaN   NaN   DBpia  NaN   \n",
       "4  http://www.ksae.org      70-80       NaN NaN   NaN   DBpia  NaN   \n",
       "\n",
       "                                    국문 초록 (Abstract)  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  환경문제에 따른 배기가스 배출저감 및 자원고갈에 따른 대안으로 향후 수소 연료전지 ...   \n",
       "3  현재 생활 필수품 중의 하나인 자동차논 많은 변화를 보이고 있다. 발전사를 살펴보면...   \n",
       "4  오늘날 급속히 변화하고 있는 자동차 기술에 대응한 자동차 기술교육의 방법을 모색하여...   \n",
       "\n",
       "                      다국어 초록 (Multilingual Abstract)  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  The researches on the crash and the fire safet...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                  목차  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  Abstract\\n1. 서론\\n2. 수소의 특성\\n3. 충돌 및 화재안전성 관련 연...  \n",
       "3                                                NaN  \n",
       "4  초록<br/>\\n1.서론<br/>\\n2.국내 자동차기술교육의 역사<br/>\\n3.민...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>제목</th>\n      <th>저자</th>\n      <th>발행기관</th>\n      <th>학술지명</th>\n      <th>권호사항</th>\n      <th>발행연도</th>\n      <th>작성언어</th>\n      <th>주제어</th>\n      <th>KDC</th>\n      <th>등재정보</th>\n      <th>...</th>\n      <th>발행기관 URL</th>\n      <th>수록면</th>\n      <th>KCI 피인용횟수</th>\n      <th>비고</th>\n      <th>중단사유</th>\n      <th>제공처</th>\n      <th>소장기관</th>\n      <th>국문 초록 (Abstract)</th>\n      <th>다국어 초록 (Multilingual Abstract)</th>\n      <th>목차</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>전기 이륜자동차 분류기준 현황 : 자동차관리법 중심</td>\n      <td>정윤재</td>\n      <td>한국자동차공학회</td>\n      <td>한국자동차공학회 Workshop</td>\n      <td>Vol.2011No.9[2011]\\r\\n</td>\n      <td>2011</td>\n      <td>Korean</td>\n      <td>NaN</td>\n      <td>556.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>http://www.ksae.org</td>\n      <td>1-14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>DBpia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>자동차 사회의 환경과 에너지 문제 = 자동차 엔진 기술의 역사적 동향</td>\n      <td>김영길(Yong Kil Kim)</td>\n      <td>한국자동차공학회</td>\n      <td>한국자동차공학회 학술대회 및 전시회</td>\n      <td>Vol.2014No.11[2014]\\r\\n</td>\n      <td>2014</td>\n      <td>Korean</td>\n      <td>Internal Combustion Engine(내연기관),Energy (에너지),...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1477-1477</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>DBpia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>수소 연료전지 자동차의 충돌 및 화재안전성 관련 연구동향 = Trends on Cr...</td>\n      <td>임재문(Jae Moon Lim),장형진(Hyung Jin Chang),김규현(Gyu...</td>\n      <td>한국자동차공학회</td>\n      <td>한국자동차공학회 춘 추계 학술대회 논문집</td>\n      <td>Vol.-No.-[2008]\\r\\n</td>\n      <td>2008</td>\n      <td>Korean</td>\n      <td>Hydrogen Fuel Cell Vehicle(수소 연료전지 자동차),Crash ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>http://www.ksae.org</td>\n      <td>1253-1258</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>DBpia</td>\n      <td>NaN</td>\n      <td>환경문제에 따른 배기가스 배출저감 및 자원고갈에 따른 대안으로 향후 수소 연료전지 ...</td>\n      <td>The researches on the crash and the fire safet...</td>\n      <td>Abstract\\n1. 서론\\n2. 수소의 특성\\n3. 충돌 및 화재안전성 관련 연...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>차세대 자동차 개발의 Plastic Hood 설계 및 CAE해석 = Plastic ...</td>\n      <td>황태원(Taewon Hwang),최치훈(Chihoon Choi),박상선(Sangsu...</td>\n      <td>한국자동차공학회</td>\n      <td>한국자동차공학회 춘 추계 학술대회 논문집</td>\n      <td>Vol.-No.-[2006]\\r\\n</td>\n      <td>2006</td>\n      <td>Korean</td>\n      <td>HOOD(본넷트),Distance(이동량),LS-DYNA(구조해석),MOLDFLOW...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>http://www.ksae.org</td>\n      <td>2032-2032</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>DBpia</td>\n      <td>NaN</td>\n      <td>현재 생활 필수품 중의 하나인 자동차논 많은 변화를 보이고 있다. 발전사를 살펴보면...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>자동차 산업의 역사와 급변하는 기술에 대응한 교육의 바람직한 방향에 관한 연구 = ...</td>\n      <td>황경수(Kyungsoo Whang)</td>\n      <td>한국자동차공학회</td>\n      <td>한국자동차공학회 Workshop</td>\n      <td>Vol.2001No.-[2001]\\r\\n</td>\n      <td>2001</td>\n      <td>Korean</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>http://www.ksae.org</td>\n      <td>70-80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>DBpia</td>\n      <td>NaN</td>\n      <td>오늘날 급속히 변화하고 있는 자동차 기술에 대응한 자동차 기술교육의 방법을 모색하여...</td>\n      <td>NaN</td>\n      <td>초록&lt;br/&gt;\\n1.서론&lt;br/&gt;\\n2.국내 자동차기술교육의 역사&lt;br/&gt;\\n3.민...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "train_data = dataset['국문 초록 (Abstract)'].dropna()\n",
    "train_data = train_data.apply(lambda x: re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣] \", \"\", x))\n",
    "\n",
    "end = time.time()\n",
    "print(f'총 소요시간:{end-start}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#너무 오래 걸림\n",
    "start = time.time()\n",
    "\n",
    "train_data_list = []\n",
    "for idx, element in enumerate(train_data.tolist()) :\n",
    "    print(idx, end=\",\")\n",
    "    r = spacing(element)\n",
    "    train_data_list.append(element)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(f'총 소요시간:{end-start}초')\n",
    "\n",
    "train_data_list\n",
    "#[spacing(x) for x in train_data.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(train_data))"
   ]
  },
  {
   "source": [
    "사용 가능한 패키지\n",
    "Soyspacing – https://github.com/lovit/soyspacing : 휴리스틱 알고리즘 기반 띄어쓰기 모델. 주어진 알고리즘으로 input으로 들어간 문장들에서 띄어쓰기 규칙을 파악하고 이를 새로운 문장에 적용. 모든 한글 문서에 광범위하게 적용할 수 있는 모델을 내기에는 한계가 있겠지만, 동질적인 주제와 형식을 가진 문서들에 대해 분석을 하는 경우 특히 유용하게 쓸 수 있을 것 같다. (특정 도메인을 위한 모델)\n",
    "\n",
    "PyKoSpacing – https://github.com/haven-jeon/PyKoSpacing : CNN에 RNN을 쌓아 올린 모델을 뉴스 데이터로 훈련. 세종 코퍼스 등 테스트 셋에서 잘 작동한다고 한다. 하지만 accuracy measure가 성능을 over represent 할 수 있을 것 같다. 대체로 띄어쓰기가 정말 난장판으로 되어있는 경우 볼만한 문서로 바꾸는데 사용할 수 있을 것 같다.\n",
    "\n",
    "TaKos (Alpha) – https://github.com/Taekyoon/takos-alpha : 앞서 첨부한 Youtube 영상에서 소개된 프로젝트. 아직 상용화까지 개발이 진행 중인 것 같다!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_kor = stopwords.words('korean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_data = []\n",
    "\n",
    "start = time.time()\n",
    "for abstract in train_data.tolist() :\n",
    "    temp_X = mecab.morphs(abstract)\n",
    "    temp_X = [word for word in temp_X if not word in stop_words_kor]\n",
    "    tokenized_data.append(temp_X)\n",
    "\n",
    "end = time.time()\n",
    "print(f'총 소요시간:{end-start}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('초록의 최대 길이:', max(len(l) for l in tokenized_data))\n",
    "print('초록의 평균 길이:', sum(map(len, tokenized_data)) / len(tokenized_data))\n",
    "\n",
    "plt.hist([len(s) for s in tokenized_data], bins=50)\n",
    "plt.xlabel('초록의 길이')\n",
    "plt.ylabel('초록의 개수')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_data, size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar(\"자율 주행\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar(\"자율주행\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.most_similar(\"하이브리드\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['주제어']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['작성언어'].value_counts()"
   ]
  },
  {
   "source": [
    "### CountVector를 위한 준비 작업 및 확인 로직 (시작)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분석대상 항목으로 발행연도, 제목, 주제어, 국문 초록 (Abstract)을 선택하고 컬럼명을 영문으로 변경함\n",
    "dataset_1 = dataset.loc[:, ['발행연도', '제목', '저자', '발행기관', '학술지명', '주제어', '국문 초록 (Abstract)', '다국어 초록 (Multilingual Abstract)']]\n",
    "dataset_1 = dataset_1.rename({'발행연도':'year', '제목':'title', '저자':'author', '발행기관':'publisher', '학술지명':'journal', '주제어':'keyword', '국문 초록 (Abstract)':'abstract_old', '다국어 초록 (Multilingual Abstract)':'others'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50568 entries, 0 to 50567\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   year          50568 non-null  int64 \n 1   title         50568 non-null  object\n 2   author        50568 non-null  object\n 3   publisher     50568 non-null  object\n 4   journal       50568 non-null  object\n 5   keyword       26933 non-null  object\n 6   abstract_old  10447 non-null  object\n 7   others        25062 non-null  object\ndtypes: int64(1), object(7)\nmemory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#국문 초록 값이 없는 건수가 전체의 80%에 해당하고 있음(잘못된 논리임)\n",
    "#하지만 제목은 초록의 함축적인 문장으로 볼 수 있기 때문에 초록이 없는 경우 제목으로 대체\n",
    "\n",
    "\n",
    "#0.주제어 예측\n",
    "#1.가짜 키워드~ 판별....\n",
    "#2.문서요약\n",
    "#-키워드 백터\n",
    "# dataset_2['keyword'].apply(get_words)\n",
    "dataset_1['abstract'] = np.where(dataset_1['abstract_old'].isnull(), dataset_1['others'], dataset_1['abstract_old'])\n",
    "#dataset_1['abstract'] = np.where(dataset_1['abstract_old'].isnull(), dataset_1['others'].apply(translate_test), dataset_1['abstract_old'])\n",
    "\n",
    "del dataset_1['abstract_old']\n",
    "del dataset_1['others']\n",
    "\n",
    "dataset_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = dataset_1[dataset_1['abstract'].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['이', '있', '하', '것', '들']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "stop_words_eng = stopwords.words('english')\n",
    "stop_words_kor = stopwords.words('korean')\n",
    "\n",
    "stop_words = []\n",
    "stop_words.extend(stop_words_kor)\n",
    "#stop_words.extend(stop_words_eng)\n",
    "\n",
    "stop_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#색인 추출\n",
    "def tokenizer_by_twitter(raw, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\"], stopword=stop_words):\n",
    "    return [\n",
    "        word for word, tag in twitter.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 그랰ㅋㅋ -> 그래ㅋㅋ\n",
    "            stem=True    # stemming 바뀌나->바뀌다\n",
    "            )\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "    ]\n",
    " \n",
    "#색인 추출\n",
    "def tokenizer_by_kkma(raw, pos=[\"NNG\",\"NNP\",\"NP\", \"VV\"], stopword=stop_words):\n",
    "    return [\n",
    "        word for word, tag in kkma.pos(raw)\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "    ]\n",
    "\n",
    "#색인 추출\n",
    "def tokenizer_by_mecab(raw, pos=[\"NNG\",\"NNP\"], stopword=stop_words):\n",
    "    return [\n",
    "        word for word, tag in mecab.pos(raw)\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab.pos('향후산업')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용하지 않음\n",
    "import re\n",
    "\n",
    "p = re.compile('[ㄱ-하ㅏ-ㅣ가-힣]+')\n",
    "f = lambda x: p.findall(x)[0].split(\",\")[0] if len(p.findall(x)) > 0  else print(x)\n",
    "dataset_3['author'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 26933 entries, 1 to 50566\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   year          26933 non-null  int64 \n 1   title         26933 non-null  object\n 2   author        26933 non-null  object\n 3   publisher     26933 non-null  object\n 4   journal       26933 non-null  object\n 5   keyword       26933 non-null  object\n 6   abstract_old  7526 non-null   object\n 7   others        17411 non-null  object\ndtypes: int64(1), object(7)\nmemory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_2 = dataset_1[dataset_1['keyword'].isna() == False]\n",
    "dataset_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018년 이후 논문\n",
    "dataset_3 = dataset_2[dataset_2['year'] >= 2016]\n",
    "dataset_3[\"keyword\"] = dataset_3[\"keyword\"].apply(lambda x: re.sub(\"[^ ㄱ-ㅎㅏ-ㅣ가-힣]+\", \" \", x).strip())\n",
    "\n",
    "#인덱스 reset\n",
    "dataset_3 = dataset_3.reset_index()\n",
    "rawdata = dataset_3['keyword'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9456\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['경량 자동차     다종소재 차체     기계적 접합   복합 접합',\n",
       " '실도로 주행 배출가스   주행특성   주행모드   질소 산화물     이동평균구간     소형자동차',\n",
       " '미래형자동차     인력양성   현장실습     차산업 교육과정',\n",
       " '임베디드 소프트웨어     자율주행         스마트카소프트웨어플랫폼     커넥티드카   인공지능',\n",
       " '디자인 변화 요인   차량 기술   생산기술   상업적 요인   미래 방향',\n",
       " '자율주행 자동차   평가 시나리오     임시운행 허가     안전성 평가항목',\n",
       " '전동화       등가 회로 모델     마일드 하이브리드 자동차   리튬 배터리',\n",
       " '제상성능 자동차 전면유리 자동차 전산유체역학 최적화',\n",
       " '차체   롤 케이지 엔진 동력전달장치   섀시 전기배선',\n",
       " '자동차 서비스   자동차 산업   미래 전략 융복합 복합단지   애프터마켓']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "print(len(rawdata))\n",
    "rawdata[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "vect = CountVectorizer(max_features = 300, max_df=0.95, min_df=10, tokenizer=tokenizer_by_mecab, ngram_range = (1, 3))\n",
    "result = vect.fit_transform(rawdata)\n",
    "print(\n",
    "    'fit_transform, (sentence {}, feature {})'.format(result.shape[0], result.shape[1])\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f'총 소요시간: {end-start}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = result.toarray()\n",
    "data = pd.DataFrame(data_array, columns= vect.get_feature_names())\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, n_iter=10000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = tsne.fit_transform(data_array.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.scatter(Z[:,0], Z[:,1])\n",
    "\n",
    "#점에 text 붙히기\n",
    "for i in range(len(vect.get_feature_names())):\n",
    "    plt.annotate(s=vect.get_feature_names()[i].encode(\"utf8\").decode(\"utf8\"), xy=(Z[i,0], Z[i,1]))\n",
    "plt.draw()\n",
    "plt.savefig('tsne.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수식이 필요함\n",
    "#기관, 사람 도메인의 내용을 가지고 수식을 통해 연관성과 그렇지 않은 경우를 판단하여 지속적인 서비스를 제공해야함\n",
    "#information 필터링/데이터 큐레이션\n",
    "\n",
    "def find_analogies(w1, w2, w3, emb, word2idx):\n",
    "    pos_word1 = emb[word2idx[w1]]\n",
    "    pos_word2 = emb[word2idx[w2]]\n",
    "    neg_word1 = emb[word2idx[w3]]\n",
    "    v0 = pos_word1 + pos_word2 - neg_word1\n",
    "\n",
    "    def dist1(a, b):\n",
    "        return np.linalg.norm(a - b)\n",
    "    def dist2(a, b):\n",
    "        return 1 - a.dot(b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "    for dist, name in [(dist1, 'Euclidean'), (dist2, 'cosine')]:\n",
    "        min_dist = float('inf')\n",
    "        best_word = ''\n",
    "        for idx, word in enumerate(word2idx):\n",
    "            if word not in (w1, w2, w3):\n",
    "                v1 = emb[idx]\n",
    "                d = dist(v0, v1)\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    best_word = word\n",
    "        print(\"closest match by\", name, \"distance:\", best_word)\n",
    "        print(w1, \"-\", w2, \"=\", w3, \"-\", best_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in enumerate(word2idx) :\n",
    "    print(word, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFM\n",
    "analogies_to_try = (\n",
    "    (\"자율주행\",\"시스템\",\"디젤\"),\n",
    "    (\"댐퍼\",\"융합\",\"자율주행\"),\n",
    ")\n",
    "\n",
    "word2idx = {word: ii for ii, word in enumerate(vect.get_feature_names())}\n",
    "for word_list in analogies_to_try:\n",
    "    print(word_list)\n",
    "    w1, w2, w3 = word_list\n",
    "    find_analogies(w1=w1, w2=w2, w3=w3, emb=Z, word2idx=word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 문장에서 뽑아낸 feature 들의 Dictionary\n",
    "features = vect.get_feature_names()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame = pd.DataFrame(result_array, columns=features)\n",
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_result = pd.concat([dataset_3, result_frame.reindex(dataset_3.index)], axis = 1)\n",
    "last_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3.to_csv(\"./dataset/count_vec.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(\n",
    "    tokenizer=tokenizer_by_mecab,\n",
    "    min_df=5,\n",
    "    sublinear_tf = True    # tf값에 1+log(tf)를 적용하여 tf값이 무한정 커지는 것을 막음\n",
    ")\n",
    "X = vectorize.fit_transform(rawdata)\n",
    "print(\n",
    "    'fit_transform, (sentence {}, feature {})'.format(X.shape[0], X.shape[1])\n",
    ")\n",
    "print(X.toarray())\n",
    "# 문장에서 뽑아낸 feature 들의 배열\n",
    "features = vectorize.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "source": [
    "### CountVector를 위한 준비 작업 및 확인 로직 (종료)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for idx, val in enumerate(rawdata):\n",
    "        if idx % 1000 == 0 :\n",
    "        print(f'{idx + 1} 개를 처리중입니다. [{val}]')\n",
    "    words = tokenizer_by_kkma(val)\n",
    "    result.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dict(count.most_common(100))\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dict(count.most_common(200))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5 = dataset_5.dropna()\n",
    "for word in words :\n",
    "    count = len(dataset_5[dataset_5['abstract'].str.contains(word)])\n",
    "    print(f'주제어: {word} / 논문수: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#키워드 를 축소 필요 \n",
    "#키워드별로 논문 개수 (논문편수 5개 이하는 제외하자)\n",
    "#https://codechacha.com/ko/python-google-translate/"
   ]
  },
  {
   "source": [
    "- from googletrans import Translator\n",
    "- translator = Translator()\n",
    "- result = translator.translate('안녕하세요.', dest=\"ja\")\n",
    "- print(result[0].text)\n",
    "\n",
    "#### 구글 번역 API가 변경되어 다음과 같은 설치 필요\n",
    "\n",
    "- $ pip uninstall googletrans\n",
    "- $ git clone https://github.com/alainrouillon/py-googletrans.git\n",
    "- $ cd ./py-googletrans\n",
    "- $ git checkout origin/feature/enhance-use-of-direct-api\n",
    "- $ python setup.py install"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.주제어 COUNT\n",
    "#2.분석대상 명확하게~ \n",
    "#3.주제어별 관계도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}